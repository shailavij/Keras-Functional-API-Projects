{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Sequence_modelling.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9b3PNw3gJDI7",
        "hcPUtmz-JDKZ",
        "MHcNqGnWJDMH",
        "1NVXF1TSJDMj",
        "H3srEhqCJDM7"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shailavij/Keras-Functional-API-Projects/blob/master/Sequence_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk88Aw4NJDIy",
        "colab_type": "code",
        "outputId": "5cafdcbf-3b07-4110-f105-5b854b7f13c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "print('GPU name: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "GPU name: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQb8nVqLJDI5",
        "colab_type": "text"
      },
      "source": [
        "# Sequence modelling \n",
        "\n",
        "## Coding tutorials\n",
        " #### 1.  The IMDb dataset\n",
        " #### 2. Padding and masking sequence data\n",
        " #### 3. The `Embedding` layer\n",
        " #### 4. The Embedding Projector\n",
        " #### 5. Recurrent neural network layers\n",
        " #### 6. Stacked RNNs and the `Bidirectional` wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b3PNw3gJDI7",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## The IMDb Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwqGZQ8WJDJF",
        "colab_type": "text"
      },
      "source": [
        "#### Load the IMDB review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3_c1LL5JDJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import imdb\n",
        "import tensorflow.keras.datasets.imdb as imdb\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9jYJCwXJDJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download and assign the data set using load_data()\n",
        "\n",
        "(x_train,y_train),(x_test,y_test)=imdb.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oCnB8UMJDJP",
        "colab_type": "text"
      },
      "source": [
        "#### Inspect the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39RwIt-pJDJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inspect the type of the data\n",
        "\n",
        "type(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Viryy_PDJDJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inspect the shape of the data\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q6E6v-FJDJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display the first dataset element input\n",
        "# Notice encoding\n",
        "x_train[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lbEqyjxJDJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display the first dataset element output\n",
        "\n",
        "y_train[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAk-PyOgJDJg",
        "colab_type": "text"
      },
      "source": [
        "#### Load dataset with different options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfzFxDj-JDJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the dataset with defaults\n",
        "imdb.load_data(path='imdb.npz',index_from=3)\n",
        "\n",
        "# ~/.keras/dataset/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuGfzZg3JDJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Limit the vocabulary to the top 500 words using num_words\n",
        "imdb.load_data(num_words=1000)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMkXgUGaJDJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ignore the top 10 most frequent words using skip_top\n",
        "\n",
        "imdb.load_data(skip_top=10,num_words=1000,oov_char=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBDAFt0FJDJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Limit the sequence lengths to 500 using maxlen\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI-Nr897LorW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Use '1' as the character that indicates the start of a sequence\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuBCKKGyJDJ7",
        "colab_type": "text"
      },
      "source": [
        "#### Explore the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gkaFf6MJDJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the imdb word index using get_word_index()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUzgAIoKJDKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# View the word index as a dictionary,\n",
        "# accounting for index_from.\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huCi_QIzJDKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Retrieve a specific word's index\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7UkZwHiJDKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# View an input sentence\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq2ID8wRJDKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the sentiment value\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcPUtmz-JDKZ",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Padding and Masking Sequence Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UggNd-8VLgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the imdb data set\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuqWhXi-JDKa",
        "colab_type": "text"
      },
      "source": [
        "#### Preprocess the data with padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWULtJ7CJDKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inspect the input data shape\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOts_k01JDKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pad the inputs to the maximum length using maxlen\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNPiMGwDJDKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inspect the output data shape\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJt56letJDKn",
        "colab_type": "text"
      },
      "source": [
        "#### Create a Masking layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdoMdifYJDKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import numpy \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8LjX9QaJDKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Masking expects to see (batch, sequence, features)\n",
        "# Create a dummy feature dimension using expand_dims\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFrgXbDrJDKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a Masking layer \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kkSzdHwJDKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pass tf_x_train to it\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuStn9s0JDK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at the dataset\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O54DVLx4JDK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at the ._keras_mask for the dataset\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo5rD5ZcJDK_",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## The Embedding layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCkBOM8mJDLA",
        "colab_type": "text"
      },
      "source": [
        "#### Create and apply an `Embedding` layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-esPcdDJDLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an embedding layer using layers.Embedding\n",
        "# Specify input_dim, output_dim, input_length\n",
        "embedding_layer= tf.keras.layers.Embedding(input_dim=501,output_dim=12)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf3B6HamJDLN",
        "colab_type": "code",
        "outputId": "1edabdfc-09fc-4016-ca02-0288a363a372",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "# Inspect an Embedding layer output for a fixed input\n",
        "# Expects an input of shape (batch, sequence, feature)\n",
        "seq_of_indices= tf.constant([[[0], [1],[5],[500]]])\n",
        "seq_of_emmedding= embedding_layer(seq_of_indices)\n",
        "seq_of_emmedding\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 1, 12), dtype=float32, numpy=\n",
              "array([[[[ 0.01912295,  0.01220428, -0.02703236, -0.0384903 ,\n",
              "          -0.00795363,  0.00937154, -0.02388804,  0.03286494,\n",
              "           0.0042765 ,  0.01916081, -0.04047575,  0.03615687]],\n",
              "\n",
              "        [[-0.02020805,  0.03766987, -0.01067548, -0.03069779,\n",
              "          -0.01433171, -0.00544282,  0.02376939, -0.02738677,\n",
              "           0.02199486, -0.01465237, -0.00361659,  0.04847847]],\n",
              "\n",
              "        [[ 0.0070874 ,  0.03779385, -0.00820453,  0.03925346,\n",
              "          -0.01704825,  0.02485527, -0.03082444, -0.00113953,\n",
              "           0.01130966,  0.01667226, -0.03050878,  0.02189085]],\n",
              "\n",
              "        [[ 0.01638808,  0.01502618, -0.00300517, -0.03867028,\n",
              "           0.03227032,  0.01639879,  0.0114466 , -0.04327686,\n",
              "          -0.03378621, -0.04900303,  0.04165428, -0.03849852]]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCcNdD4vXOin",
        "colab_type": "code",
        "outputId": "0fdf8b99-a734-4755-e592-6fdbe927eda8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "seq_of_indices"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 1), dtype=int32, numpy=\n",
              "array([[[  0],\n",
              "        [  1],\n",
              "        [  5],\n",
              "        [500]]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ualmsaPpJDLV",
        "colab_type": "code",
        "outputId": "85e436bb-0dc8-4714-bf66-7d84668156cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "# Inspect the Embedding layer weights using get_weights()\n",
        "embedding_layer.get_weights()[0]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.01912295,  0.01220428, -0.02703236, ...,  0.01916081,\n",
              "        -0.04047575,  0.03615687],\n",
              "       [-0.02020805,  0.03766987, -0.01067548, ..., -0.01465237,\n",
              "        -0.00361659,  0.04847847],\n",
              "       [-0.02952589,  0.00343388,  0.04664264, ...,  0.00517816,\n",
              "         0.00536524,  0.04436662],\n",
              "       ...,\n",
              "       [ 0.02414621,  0.00709542, -0.0383075 , ...,  0.00615542,\n",
              "        -0.03499434, -0.01105471],\n",
              "       [ 0.02097888,  0.04013235,  0.04211752, ..., -0.04504815,\n",
              "        -0.00092714,  0.01567905],\n",
              "       [ 0.01638808,  0.01502618, -0.00300517, ..., -0.04900303,\n",
              "         0.04165428, -0.03849852]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wadlt3AJDLX",
        "colab_type": "code",
        "outputId": "90c3c6fb-268b-4b44-c36c-a5767d636785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Get the embedding for the 14th index\n",
        "\n",
        "embedding_layer.get_weights()[0][14,:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.02442672,  0.03394592, -0.01316215,  0.04986267, -0.01826004,\n",
              "       -0.02495662,  0.01667837, -0.01030581,  0.04360006,  0.01641582,\n",
              "       -0.02035528, -0.0389078 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFuhReOm9xF7",
        "colab_type": "text"
      },
      "source": [
        "#### Create and apply an `Embedding` layer that uses `mask_zero=True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKYwKT_I-H2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a layer that uses the mask_zero kwarg\n",
        "\n",
        "masking_embedding_layer= tf.keras.layers.Embedding(input_dim=501,output_dim=16,mask_zero=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hc1zx6A-H6R",
        "colab_type": "code",
        "outputId": "9da67f28-5212-4544-f428-6c02cf29b068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# Apply this layer to the sequence and see the _keras_mask property\n",
        "\n",
        "mask_seq_embedding=masking_embedding_layer(seq_of_indices)\n",
        "mask_seq_embedding._keras_mask"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 1), dtype=bool, numpy=\n",
              "array([[[False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True]]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUG6LF1MJDL0",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## The Embedding Projector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zna3TCoTAu00",
        "colab_type": "text"
      },
      "source": [
        "#### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPKYrlepAxPV",
        "colab_type": "code",
        "outputId": "5c8caee4-6621-4fb6-99c2-5416d3efdbcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnSBOkj4xmlS",
        "colab_type": "code",
        "outputId": "1c0a86c0-ac4b-4323-8c17-f46df53125db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBAX9ENDBFFE",
        "colab_type": "text"
      },
      "source": [
        "#### Load and preprocess the IMDb data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo5qBbDDBIdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGpymnb2BIiR",
        "colab_type": "code",
        "outputId": "fc3d64f7-1eb7-464a-f2b2-8a004edb255f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load the dataset\n",
        "(x_train,y_train),(x_test,y_test)= get_and_pad_imdb_dataset()\n",
        "x_train.shape\n",
        "x_train.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 2494)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EtU2vK0BLts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtkIEIdRBSxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the word index\n",
        "imdb_word_index= get_imdb_word_index()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur2fp10YBS6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Swap the keys and values of the word index\n",
        "\n",
        "inv_imdb_word_index = {value:key  for key,value in imdb_word_index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cquirCA8BS99",
        "colab_type": "code",
        "outputId": "a1764d12-9fbf-4fa5-a9fa-f71612b98b8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# View the first dataset example sentence\n",
        "[inv_imdb_word_index[index] for index in x_train[10000] if index>2]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'think',\n",
              " 'this',\n",
              " 'is',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'weakest',\n",
              " 'of',\n",
              " 'the',\n",
              " 'kenneth',\n",
              " 'branagh',\n",
              " 'works',\n",
              " 'after',\n",
              " 'such',\n",
              " 'great',\n",
              " 'efforts',\n",
              " 'as',\n",
              " 'much',\n",
              " 'about',\n",
              " 'nothing',\n",
              " 'etc',\n",
              " 'i',\n",
              " 'thought',\n",
              " 'this',\n",
              " 'was',\n",
              " 'poor',\n",
              " 'the',\n",
              " 'cast',\n",
              " 'was',\n",
              " 'weaker',\n",
              " 'alicia',\n",
              " 'but',\n",
              " 'my',\n",
              " 'biggest',\n",
              " 'was',\n",
              " 'that',\n",
              " 'they',\n",
              " 'messed',\n",
              " 'with',\n",
              " 'the',\n",
              " 'work',\n",
              " 'and',\n",
              " 'cut',\n",
              " 'out',\n",
              " 'some',\n",
              " 'of',\n",
              " 'the',\n",
              " 'play',\n",
              " 'to',\n",
              " 'put',\n",
              " 'in',\n",
              " 'the',\n",
              " 'musical',\n",
              " 'dance',\n",
              " 'sequences',\n",
              " 'br',\n",
              " 'br',\n",
              " 'you',\n",
              " 'just',\n",
              " \"don't\",\n",
              " 'do',\n",
              " 'shakespeare',\n",
              " 'and',\n",
              " 'then',\n",
              " 'mess',\n",
              " 'with',\n",
              " 'the',\n",
              " 'play',\n",
              " 'sorry',\n",
              " 'but',\n",
              " 'that',\n",
              " 'is',\n",
              " 'just',\n",
              " 'wrong',\n",
              " 'i',\n",
              " 'love',\n",
              " 'some',\n",
              " 'cole',\n",
              " 'porter',\n",
              " 'just',\n",
              " 'like',\n",
              " 'the',\n",
              " 'next',\n",
              " 'person',\n",
              " 'but',\n",
              " \"don't\",\n",
              " 'mess',\n",
              " 'with',\n",
              " 'the',\n",
              " 'shakespeare',\n",
              " 'skip',\n",
              " 'this',\n",
              " 'and',\n",
              " 'watch',\n",
              " 'books',\n",
              " 'if',\n",
              " 'you',\n",
              " 'want',\n",
              " 'to',\n",
              " 'see',\n",
              " 'a',\n",
              " 'brilliant',\n",
              " 'shakespearean',\n",
              " 'adaptation',\n",
              " 'of',\n",
              " 'the']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrE0rpCVJDL1",
        "colab_type": "text"
      },
      "source": [
        "#### Build an Embedding layer into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPUfv9kjJDL1",
        "colab_type": "code",
        "outputId": "74b7acc3-3c69-4c9a-e974-a08eb30624f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Get the maximum token value\n",
        "max_index_value= max(imdb_word_index.values())\n",
        "max_index_value\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa_fsV81liu-",
        "colab_type": "code",
        "outputId": "9db6ec24-a392-4bed-e556-c3fe35344c8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "imdb_word_index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'woods': 1410,\n",
              " 'hanging': 2347,\n",
              " 'woody': 2291,\n",
              " 'arranged': 6748,\n",
              " 'bringing': 2340,\n",
              " 'wooden': 1638,\n",
              " 'errors': 4012,\n",
              " 'dialogs': 3232,\n",
              " 'kids': 361,\n",
              " 'uplifting': 5036,\n",
              " 'controversy': 7095,\n",
              " 'projection': 9880,\n",
              " 'stern': 7182,\n",
              " 'morally': 5623,\n",
              " 'wang': 5285,\n",
              " 'want': 180,\n",
              " 'travel': 2105,\n",
              " 'barbra': 6704,\n",
              " 'dinosaurs': 3932,\n",
              " 'wrong': 354,\n",
              " 'subplots': 4762,\n",
              " 'welcomed': 9094,\n",
              " 'butcher': 6705,\n",
              " 'fit': 1182,\n",
              " 'screaming': 1929,\n",
              " 'fix': 4289,\n",
              " 'hurting': 9656,\n",
              " 'effects': 301,\n",
              " 'barton': 8777,\n",
              " 'ingrid': 6194,\n",
              " 'adapt': 7918,\n",
              " 'disturbed': 4013,\n",
              " 'purpose': 1287,\n",
              " 'olds': 6794,\n",
              " 'needed': 886,\n",
              " 'master': 1299,\n",
              " 'positively': 5401,\n",
              " 'zatoichi': 9838,\n",
              " 'feeling': 546,\n",
              " 'affairs': 5624,\n",
              " 'wholesome': 7801,\n",
              " 'cinematic': 1359,\n",
              " 'tech': 4990,\n",
              " 'saying': 659,\n",
              " 'padded': 8424,\n",
              " 'tempted': 5747,\n",
              " 'plate': 7478,\n",
              " 'altogether': 3901,\n",
              " 'lds': 8778,\n",
              " 'nicely': 1779,\n",
              " 'mummy': 4590,\n",
              " 'lots': 774,\n",
              " 'lotr': 9261,\n",
              " 'irs': 9881,\n",
              " 'ira': 6889,\n",
              " 'discipline': 7695,\n",
              " 'nature': 875,\n",
              " 'superficial': 3902,\n",
              " 'extent': 2825,\n",
              " 'bothers': 8779,\n",
              " 'much': 75,\n",
              " 'spit': 6261,\n",
              " 'arkin': 7366,\n",
              " 'doubts': 4991,\n",
              " 'spin': 3086,\n",
              " 'hong': 2578,\n",
              " 'academic': 9096,\n",
              " 'corporate': 4451,\n",
              " 'hal': 4313,\n",
              " 'ham': 4894,\n",
              " 'had': 68,\n",
              " 'has': 46,\n",
              " 'hat': 2403,\n",
              " 'crowd': 2292,\n",
              " 'crown': 6629,\n",
              " 'bottom': 1323,\n",
              " 'starring': 1183,\n",
              " 'marshall': 5342,\n",
              " 'honeymoon': 9097,\n",
              " 'shoots': 3233,\n",
              " 'fabric': 8291,\n",
              " 'raped': 3539,\n",
              " 'rapes': 8928,\n",
              " \"else's\": 5926,\n",
              " 'martian': 7255,\n",
              " 'passenger': 9459,\n",
              " 'disgrace': 6043,\n",
              " 'barrymore': 5122,\n",
              " 'cambodia': 9882,\n",
              " 'palma': 5560,\n",
              " 'explosions': 3977,\n",
              " 'loren': 8061,\n",
              " 'shootout': 6706,\n",
              " 'chain': 3628,\n",
              " 'whoever': 2499,\n",
              " 'chair': 3038,\n",
              " 'ballet': 4519,\n",
              " 'macho': 5625,\n",
              " 'jerk': 3398,\n",
              " 'gloomy': 7367,\n",
              " 'locked': 2896,\n",
              " 'exact': 2590,\n",
              " 'minute': 785,\n",
              " 'celebrated': 6540,\n",
              " 'unintentionally': 3385,\n",
              " 'climbs': 9098,\n",
              " 'honour': 9657,\n",
              " 'address': 5516,\n",
              " 'benson': 9460,\n",
              " 'cusack': 3842,\n",
              " 'opposed': 3629,\n",
              " 'following': 1044,\n",
              " 'convincingly': 4520,\n",
              " 'surfing': 4254,\n",
              " 'jim': 1239,\n",
              " 'quarter': 6541,\n",
              " 'entering': 6262,\n",
              " 'seriously': 614,\n",
              " 'raunchy': 7819,\n",
              " 'grandma': 7096,\n",
              " 'modest': 6110,\n",
              " 'spoken': 2849,\n",
              " 'concert': 3251,\n",
              " 'lingering': 8426,\n",
              " 'snatch': 9099,\n",
              " \"miyazaki's\": 9262,\n",
              " 'wandering': 4634,\n",
              " 'turned': 678,\n",
              " 'turner': 3767,\n",
              " 'opposite': 1960,\n",
              " 'grateful': 6088,\n",
              " 'inconsistent': 5561,\n",
              " 'imagined': 3791,\n",
              " 'enthralled': 9883,\n",
              " 'tsui': 8598,\n",
              " 'menacing': 3540,\n",
              " 'convoluted': 3659,\n",
              " 'millionaire': 5287,\n",
              " 'west': 1262,\n",
              " 'motives': 4203,\n",
              " 'photos': 4452,\n",
              " 'unlikeable': 6111,\n",
              " 'technology': 2130,\n",
              " 'otto': 6987,\n",
              " 'visually': 2008,\n",
              " 'being': 111,\n",
              " 'grounded': 9354,\n",
              " 'excuses': 6877,\n",
              " 'sums': 5288,\n",
              " 'traffic': 5846,\n",
              " 'sensational': 8427,\n",
              " 'satisfactory': 8780,\n",
              " 'substance': 2326,\n",
              " 'thailand': 7696,\n",
              " 'hopkins': 5676,\n",
              " 'sealed': 9658,\n",
              " 'brazilian': 8062,\n",
              " 'bubble': 6707,\n",
              " 'wits': 9263,\n",
              " 'societal': 9659,\n",
              " 'with': 18,\n",
              " 'abused': 5232,\n",
              " 'rage': 3979,\n",
              " 'tripe': 5173,\n",
              " 'dirty': 1640,\n",
              " 'watches': 3630,\n",
              " 'watcher': 7578,\n",
              " 'ensuing': 9884,\n",
              " 'watched': 295,\n",
              " 'cream': 5233,\n",
              " 'waving': 9264,\n",
              " 'natalie': 6263,\n",
              " 'tricks': 3350,\n",
              " 'caused': 2163,\n",
              " 'beware': 5517,\n",
              " 'causes': 2905,\n",
              " 'nora': 8781,\n",
              " 'norm': 5796,\n",
              " 'sans': 9461,\n",
              " 'sang': 6795,\n",
              " 'sand': 6438,\n",
              " 'sane': 7920,\n",
              " 'leia': 9885,\n",
              " 'portrays': 2234,\n",
              " 'traumatized': 9265,\n",
              " 'more': 52,\n",
              " 'company': 1168,\n",
              " 'learn': 849,\n",
              " 'knocked': 5289,\n",
              " 'huge': 665,\n",
              " 'hugo': 7921,\n",
              " 'hugh': 3933,\n",
              " 'scifi': 6195,\n",
              " 'brett': 7579,\n",
              " 'resemble': 5123,\n",
              " 'paper': 2299,\n",
              " 'scott': 1090,\n",
              " 'colleague': 7697,\n",
              " 'gadget': 4314,\n",
              " \"victoria's\": 9462,\n",
              " 'shocking': 1620,\n",
              " 'ernie': 7580,\n",
              " 'research': 2300,\n",
              " '1990s': 5973,\n",
              " 'saint': 5562,\n",
              " \"paul's\": 9980,\n",
              " 'word': 680,\n",
              " 'blond': 4383,\n",
              " 'understands': 5626,\n",
              " 'overwhelmed': 9100,\n",
              " 'indifference': 9660,\n",
              " 'lombard': 9661,\n",
              " 'pleasures': 8793,\n",
              " 'exercise': 3434,\n",
              " 'insane': 2139,\n",
              " 'callahan': 9463,\n",
              " 'objects': 5343,\n",
              " 'retarded': 2999,\n",
              " 'illiterate': 9266,\n",
              " 'bell': 4014,\n",
              " 'bela': 4678,\n",
              " 'adaptation': 1252,\n",
              " 'luis': 6044,\n",
              " 'belt': 5847,\n",
              " 'satire': 2005,\n",
              " 'geoffrey': 8452,\n",
              " 'treatment': 2198,\n",
              " 'awake': 4140,\n",
              " '33': 9632,\n",
              " 'pressed': 7368,\n",
              " '30': 1087,\n",
              " 'tin': 8171,\n",
              " 'parents': 845,\n",
              " 'couple': 377,\n",
              " 'pounds': 5677,\n",
              " 'chorus': 4315,\n",
              " 'behave': 4485,\n",
              " 'mouth': 1641,\n",
              " 'terrorists': 4846,\n",
              " 'into': 82,\n",
              " 'katie': 8366,\n",
              " 'atlantis': 4015,\n",
              " 'singer': 1949,\n",
              " 'atlantic': 8063,\n",
              " 'paired': 8599,\n",
              " \"chan's\": 9267,\n",
              " 'haunt': 7369,\n",
              " 'puzzling': 9268,\n",
              " 'creasy': 7922,\n",
              " 'detectives': 5927,\n",
              " 'turkish': 7480,\n",
              " 'dickinson': 8930,\n",
              " \"show's\": 3768,\n",
              " 'cannibals': 8600,\n",
              " 'video': 373,\n",
              " 'dynamics': 6890,\n",
              " 'victor': 2272,\n",
              " 'flowing': 8064,\n",
              " 'orleans': 5096,\n",
              " 'makes': 165,\n",
              " 'maker': 3010,\n",
              " 'confidence': 4453,\n",
              " 'comedy': 211,\n",
              " 'intelligent': 1088,\n",
              " 'democracy': 9430,\n",
              " 'insight': 2617,\n",
              " \"wife's\": 5077,\n",
              " 'derivative': 6276,\n",
              " 'snake': 4016,\n",
              " 'denzel': 3386,\n",
              " 'books': 1150,\n",
              " 'bigfoot': 8429,\n",
              " 'witness': 2412,\n",
              " \"'\": 757,\n",
              " 'greedy': 4635,\n",
              " 'prepare': 5402,\n",
              " 'could': 99,\n",
              " 'lumet': 4847,\n",
              " 'interests': 4992,\n",
              " 'gays': 9101,\n",
              " 'false': 2555,\n",
              " 'tonight': 4486,\n",
              " 'depict': 6356,\n",
              " 'sinatra': 2389,\n",
              " 'placement': 8292,\n",
              " 'tape': 2213,\n",
              " 'riding': 3052,\n",
              " 'stuff': 537,\n",
              " 'guessing': 3098,\n",
              " 'frame': 2121,\n",
              " 'destiny': 4204,\n",
              " 'nuclear': 3477,\n",
              " 'preminger': 6891,\n",
              " 'staring': 4487,\n",
              " 'marty': 4896,\n",
              " 'boyer': 6542,\n",
              " 'english': 630,\n",
              " 'genetic': 8782,\n",
              " 'hateful': 6797,\n",
              " 'greater': 2797,\n",
              " 'off': 124,\n",
              " 'crack': 4079,\n",
              " 'become': 412,\n",
              " 'recognition': 4636,\n",
              " 'morris': 4848,\n",
              " 'passion': 1796,\n",
              " 'imaginary': 7264,\n",
              " 'union': 3616,\n",
              " 'swimming': 4418,\n",
              " 'letters': 4454,\n",
              " 'pairing': 8172,\n",
              " 'peters': 5037,\n",
              " 'stopping': 5563,\n",
              " 'moonstruck': 8783,\n",
              " 'tossed': 6264,\n",
              " 'evident': 3522,\n",
              " 'excitement': 2317,\n",
              " 'garbo': 4941,\n",
              " 'problem': 438,\n",
              " 'nonetheless': 2934,\n",
              " 'details': 1372,\n",
              " 'exposure': 4993,\n",
              " 'dave': 3832,\n",
              " 'strings': 5848,\n",
              " 'compete': 6112,\n",
              " 'villainous': 7581,\n",
              " 'madsen': 7682,\n",
              " 'integrity': 5038,\n",
              " 'stinks': 4384,\n",
              " 'porno': 4521,\n",
              " 'worth': 289,\n",
              " 'progression': 8065,\n",
              " 'samurai': 3631,\n",
              " 'machines': 3868,\n",
              " 'viewings': 4718,\n",
              " 'equals': 9537,\n",
              " 'achieve': 2714,\n",
              " '1991': 6046,\n",
              " '1990': 4522,\n",
              " '1993': 5039,\n",
              " '1992': 7370,\n",
              " '1995': 5124,\n",
              " '1994': 6113,\n",
              " 'divorced': 6283,\n",
              " '1996': 4141,\n",
              " '1999': 4205,\n",
              " '1998': 6630,\n",
              " 'era': 998,\n",
              " 'nuts': 4764,\n",
              " 'ladder': 5403,\n",
              " 'vera': 7108,\n",
              " 'schneider': 7265,\n",
              " 'davies': 3769,\n",
              " 'innovative': 3971,\n",
              " 'production': 364,\n",
              " 'understated': 4637,\n",
              " 'reasonably': 3715,\n",
              " 'routines': 6708,\n",
              " 'reasonable': 3792,\n",
              " 'daniel': 2273,\n",
              " \"character's\": 1729,\n",
              " 'flawless': 3561,\n",
              " 'another': 159,\n",
              " 'illustrate': 8784,\n",
              " \"o'toole\": 9886,\n",
              " 'seduction': 9271,\n",
              " 'dogs': 2514,\n",
              " 'cabin': 2815,\n",
              " 'historical': 1378,\n",
              " 'enchanted': 7371,\n",
              " 'convenient': 7698,\n",
              " 'subjects': 4045,\n",
              " 'swamp': 9465,\n",
              " 'aunt': 2964,\n",
              " 'haunted': 2367,\n",
              " 'runs': 1128,\n",
              " 'horrendous': 3387,\n",
              " 'draws': 3770,\n",
              " 'drawn': 1308,\n",
              " 'encounters': 3266,\n",
              " 'handful': 3515,\n",
              " 'kitchen': 3903,\n",
              " 'essentially': 2026,\n",
              " 'han': 8060,\n",
              " 'tone': 1162,\n",
              " 'imaginative': 3267,\n",
              " 'condescending': 9272,\n",
              " 'tons': 3399,\n",
              " 'massive': 2556,\n",
              " 'tony': 1222,\n",
              " 'unlikely': 2387,\n",
              " 'brilliantly': 2104,\n",
              " 'apparently': 683,\n",
              " 'survival': 4097,\n",
              " 'fuss': 8601,\n",
              " 'quentin': 6631,\n",
              " 'humble': 4488,\n",
              " 'mid': 1695,\n",
              " 'thanks': 1215,\n",
              " 'similarities': 4350,\n",
              " 'sparse': 9466,\n",
              " 'night': 313,\n",
              " 'jacques': 6989,\n",
              " 'attorney': 4816,\n",
              " 'rendering': 7699,\n",
              " 'czech': 8425,\n",
              " 'captive': 8430,\n",
              " 'test': 2180,\n",
              " 'tess': 8066,\n",
              " 'songs': 689,\n",
              " 'concept': 1119,\n",
              " 'battle': 984,\n",
              " 'hurry': 8604,\n",
              " 'rebecca': 9273,\n",
              " 'cunningham': 7097,\n",
              " 'turns': 504,\n",
              " 'gun': 1055,\n",
              " 'gus': 7266,\n",
              " 'gut': 5564,\n",
              " 'guy': 231,\n",
              " 'rapist': 5748,\n",
              " 'shares': 5518,\n",
              " 'shared': 5344,\n",
              " \"hadn't\": 1868,\n",
              " 'teaches': 5290,\n",
              " 'teacher': 1749,\n",
              " 'sending': 5678,\n",
              " 'franklin': 6892,\n",
              " 'plotted': 8431,\n",
              " 'regardless': 3562,\n",
              " 'extra': 1726,\n",
              " 'woefully': 8173,\n",
              " 'chip': 8174,\n",
              " 'lacks': 1502,\n",
              " 'discussion': 3771,\n",
              " 'kurt': 3198,\n",
              " 'chops': 7923,\n",
              " 'brain': 1223,\n",
              " 'still': 130,\n",
              " 'drop': 2439,\n",
              " 'challenged': 5234,\n",
              " 'yeah': 1242,\n",
              " 'challenges': 5458,\n",
              " 'year': 290,\n",
              " 'gibson': 8293,\n",
              " 'transition': 4591,\n",
              " 'suffice': 4916,\n",
              " 'romania': 8605,\n",
              " 'flipping': 8953,\n",
              " 'tomorrow': 5519,\n",
              " 'seymour': 6758,\n",
              " 'brains': 4080,\n",
              " 'professionals': 7098,\n",
              " 'transferred': 9887,\n",
              " 'importantly': 3516,\n",
              " 'premiered': 8432,\n",
              " 'teamed': 9662,\n",
              " 'burst': 5565,\n",
              " 'colours': 6266,\n",
              " 'madness': 3000,\n",
              " 'foreboding': 8606,\n",
              " 'inexplicable': 5749,\n",
              " 'exploit': 6470,\n",
              " 'charismatic': 3388,\n",
              " 'dictator': 8433,\n",
              " 'elvis': 3478,\n",
              " 'offbeat': 6357,\n",
              " 'develop': 2060,\n",
              " 'food': 1643,\n",
              " 'death': 340,\n",
              " 'earnest': 6358,\n",
              " 'fortune': 3199,\n",
              " 'fully': 1313,\n",
              " 'verbal': 6893,\n",
              " 'exposed': 3772,\n",
              " 'exposes': 9888,\n",
              " 'francis': 4803,\n",
              " \"isn't\": 217,\n",
              " 'pitched': 7924,\n",
              " 'freddy': 2280,\n",
              " 'fools': 6798,\n",
              " 'poor': 337,\n",
              " 'pool': 3072,\n",
              " 'corey': 7183,\n",
              " 'overseas': 9468,\n",
              " 'robert': 669,\n",
              " 'thoughtful': 4352,\n",
              " 'religious': 1735,\n",
              " 'decide': 1196,\n",
              " 'ass': 1994,\n",
              " 'streets': 1985,\n",
              " 'bass': 9469,\n",
              " 'excess': 5849,\n",
              " 'advertising': 4592,\n",
              " 'cathy': 9663,\n",
              " 'heroic': 3817,\n",
              " 'budgets': 6440,\n",
              " 'reject': 7969,\n",
              " 'surpasses': 9470,\n",
              " 'criticize': 7099,\n",
              " 'anytime': 6799,\n",
              " 'roommates': 9102,\n",
              " 'absence': 3818,\n",
              " \"haven't\": 773,\n",
              " 'ninja': 4849,\n",
              " 'bless': 8294,\n",
              " 'fairy': 2446,\n",
              " 'heavy': 1184,\n",
              " 'jolly': 9103,\n",
              " 'lord': 1634,\n",
              " 'earns': 8608,\n",
              " 'hapless': 5679,\n",
              " 'american': 297,\n",
              " 'visions': 5566,\n",
              " 'trapped': 2604,\n",
              " 'toward': 1840,\n",
              " 'randomly': 4850,\n",
              " 'organs': 9471,\n",
              " 'caliber': 4897,\n",
              " 'physics': 5680,\n",
              " 'stalked': 7184,\n",
              " 'phenomenon': 5681,\n",
              " 'stalker': 5850,\n",
              " 'heavens': 9104,\n",
              " 'competing': 9889,\n",
              " 'imitating': 9155,\n",
              " 'fluff': 5627,\n",
              " 'hype': 3400,\n",
              " 'locale': 8434,\n",
              " 'portrait': 3212,\n",
              " 'locals': 5750,\n",
              " 'abruptly': 6196,\n",
              " 'league': 2755,\n",
              " \"wouldn't\": 585,\n",
              " 'empty': 1895,\n",
              " 'juice': 7925,\n",
              " 'match': 1013,\n",
              " 'grant': 2106,\n",
              " 'sensual': 8076,\n",
              " 'grand': 1757,\n",
              " 'composition': 7268,\n",
              " 'classmates': 8175,\n",
              " 'obviously': 539,\n",
              " 'synopsis': 3934,\n",
              " 'reviewed': 6800,\n",
              " 'reviewer': 2214,\n",
              " 'showing': 799,\n",
              " 'sketch': 5404,\n",
              " 'lips': 4046,\n",
              " 'towards': 948,\n",
              " 'silence': 3541,\n",
              " 'alison': 5405,\n",
              " 'placing': 9105,\n",
              " 'ideals': 7842,\n",
              " 'similar': 728,\n",
              " 'ordered': 5174,\n",
              " 'fears': 3563,\n",
              " 'department': 2549,\n",
              " 'smiles': 5851,\n",
              " 'unfunny': 1959,\n",
              " 'riders': 8233,\n",
              " 'telling': 978,\n",
              " 'yourselves': 9890,\n",
              " 'watered': 9106,\n",
              " 'jump': 1782,\n",
              " 'notwithstanding': 8785,\n",
              " 'vampire': 1361,\n",
              " 'lugosi': 2783,\n",
              " 'clark': 2594,\n",
              " 'manage': 1920,\n",
              " 'clara': 6543,\n",
              " 'camera': 369,\n",
              " 'boards': 8295,\n",
              " 'meek': 8067,\n",
              " 'servants': 6359,\n",
              " 'meet': 908,\n",
              " 'pulling': 3660,\n",
              " 'sought': 6441,\n",
              " 'orson': 4419,\n",
              " 'rohmer': 9472,\n",
              " 'sentiments': 9891,\n",
              " 'ronald': 6267,\n",
              " 'scoop': 6442,\n",
              " 'favourites': 7481,\n",
              " \"its'\": 9664,\n",
              " 'university': 3435,\n",
              " 'slide': 6443,\n",
              " 'special': 317,\n",
              " 'butch': 6444,\n",
              " 'obsessive': 6632,\n",
              " 'darkly': 8068,\n",
              " 'jill': 6360,\n",
              " 'times': 210,\n",
              " 'timed': 8176,\n",
              " 'bitch': 5459,\n",
              " 'wrapped': 4560,\n",
              " 'hines': 7700,\n",
              " 'bastard': 8435,\n",
              " 'battles': 3352,\n",
              " 'mansion': 3024,\n",
              " 'repeated': 2447,\n",
              " 'manga': 8436,\n",
              " 'unfinished': 9665,\n",
              " 'sheriff': 2248,\n",
              " 'hector': 9163,\n",
              " 'won': 1198,\n",
              " 'cameos': 3200,\n",
              " 'inherited': 9274,\n",
              " 'episodes': 671,\n",
              " 'ken': 3661,\n",
              " 'kicking': 4561,\n",
              " 'key': 1316,\n",
              " 'limits': 4316,\n",
              " 'cena': 7701,\n",
              " 'troopers': 8296,\n",
              " 'controlled': 5406,\n",
              " 'surface': 2557,\n",
              " 'examined': 8931,\n",
              " 'http': 5751,\n",
              " 'riff': 7926,\n",
              " 'montages': 9473,\n",
              " 'increasingly': 3436,\n",
              " 'distant': 3608,\n",
              " 'gamut': 9834,\n",
              " 'disappearance': 8069,\n",
              " 'demonstrates': 5628,\n",
              " 'cradle': 8932,\n",
              " 'demonstrated': 6709,\n",
              " 'limitations': 6197,\n",
              " 'unhinged': 7618,\n",
              " 'nightclub': 6445,\n",
              " 'pointless': 1148,\n",
              " 'additional': 5460,\n",
              " 'gain': 3234,\n",
              " 'highest': 4081,\n",
              " 'kisses': 9892,\n",
              " 'beats': 3935,\n",
              " 'education': 4420,\n",
              " 'disasters': 8929,\n",
              " 'foil': 7185,\n",
              " 'consists': 3201,\n",
              " 'sorry': 805,\n",
              " 'void': 6990,\n",
              " 'suspenseful': 2569,\n",
              " 'herbert': 6991,\n",
              " 'unrelated': 5683,\n",
              " 'enhance': 6801,\n",
              " 'iturbi': 7372,\n",
              " 'kidnap': 7100,\n",
              " 'blandings': 7927,\n",
              " 'meg': 5798,\n",
              " 'mel': 3773,\n",
              " 'men': 348,\n",
              " 'mitchell': 3716,\n",
              " 'robertson': 7269,\n",
              " 'berlin': 4455,\n",
              " 'shahid': 7732,\n",
              " 'room': 672,\n",
              " 'roof': 5369,\n",
              " 'movies': 101,\n",
              " 'exceptions': 5629,\n",
              " 'root': 3662,\n",
              " 'titular': 7802,\n",
              " 'gordon': 2235,\n",
              " 'vicious': 3838,\n",
              " 'third': 839,\n",
              " 'fable': 9107,\n",
              " 'budding': 8177,\n",
              " 'personal': 964,\n",
              " 'crew': 1050,\n",
              " 'anil': 6300,\n",
              " 'combination': 2220,\n",
              " 'one': 30,\n",
              " 'forgot': 2737,\n",
              " 'aids': 4421,\n",
              " 'comedies': 1289,\n",
              " 'mandy': 7702,\n",
              " 'uses': 1076,\n",
              " 'floors': 9666,\n",
              " 'downside': 9667,\n",
              " 'gandolfini': 8178,\n",
              " 'begins': 777,\n",
              " 'mario': 4385,\n",
              " 'maria': 2906,\n",
              " 'zealand': 9108,\n",
              " 'mildred': 4048,\n",
              " 'testing': 7703,\n",
              " 'narrated': 6992,\n",
              " 'guaranteed': 5522,\n",
              " 'represented': 4358,\n",
              " 'quinn': 5799,\n",
              " 'mathieu': 6268,\n",
              " 'asks': 1642,\n",
              " 'entered': 5977,\n",
              " 'lovely': 1333,\n",
              " 'locations': 1978,\n",
              " 'lionel': 6993,\n",
              " 'ugly': 1557,\n",
              " 'cant': 2487,\n",
              " 'realizing': 4353,\n",
              " 'ella': 9475,\n",
              " 'programs': 5871,\n",
              " 'failing': 3717,\n",
              " 'reese': 8297,\n",
              " 'yours': 6446,\n",
              " 'assigned': 4942,\n",
              " 'fighters': 8437,\n",
              " 'goodman': 8298,\n",
              " 'stunts': 3288,\n",
              " 'nude': 2515,\n",
              " 'dean': 2642,\n",
              " 'deal': 854,\n",
              " 'deaf': 5079,\n",
              " 'dear': 3213,\n",
              " 'shakespeare': 2281,\n",
              " 'confrontation': 5126,\n",
              " 'afternoon': 2654,\n",
              " 'automatically': 5346,\n",
              " 'down': 179,\n",
              " 'narration': 2558,\n",
              " 'editor': 3793,\n",
              " 'creation': 3564,\n",
              " 'batman': 1353,\n",
              " 'landing': 5127,\n",
              " 'feminine': 6894,\n",
              " 'awhile': 5235,\n",
              " 'happening': 1447,\n",
              " 'pseudo': 3904,\n",
              " 'restored': 4638,\n",
              " 'father': 335,\n",
              " 'turgid': 9894,\n",
              " 'talked': 3542,\n",
              " 'targets': 6994,\n",
              " 'suspect': 1780,\n",
              " 'box': 952,\n",
              " 'boy': 429,\n",
              " 'maguire': 9476,\n",
              " 'bow': 5630,\n",
              " 'bon': 8609,\n",
              " 'boo': 7803,\n",
              " 'bob': 2045,\n",
              " 'teenage': 1666,\n",
              " 'transplant': 8299,\n",
              " 'drags': 3464,\n",
              " 'dennis': 2800,\n",
              " 'snl': 4489,\n",
              " 'blooded': 6447,\n",
              " 'police': 567,\n",
              " 'policy': 6895,\n",
              " 'tucker': 9668,\n",
              " 'lunch': 6802,\n",
              " 'elephants': 8786,\n",
              " 'ajay': 7482,\n",
              " 'stanwyck': 3333,\n",
              " 'carnival': 9109,\n",
              " 'frequent': 4851,\n",
              " 'first': 85,\n",
              " 'fleeing': 8933,\n",
              " 'speaking': 1385,\n",
              " 'kevin': 1841,\n",
              " 'complexity': 4639,\n",
              " 'shocked': 2413,\n",
              " 'shocker': 8300,\n",
              " '200': 6304,\n",
              " 'arguing': 6544,\n",
              " 'angst': 5567,\n",
              " 'harvey': 4354,\n",
              " 'russian': 1765,\n",
              " 'treasure': 2527,\n",
              " 'travesty': 4994,\n",
              " 'enthusiasm': 4804,\n",
              " 'get': 78,\n",
              " 'gee': 9110,\n",
              " 'gen': 8610,\n",
              " 'gem': 1527,\n",
              " 'london': 1315,\n",
              " 'seat': 2223,\n",
              " 'declares': 9895,\n",
              " 'seal': 9275,\n",
              " 'wonder': 593,\n",
              " 'satisfying': 2348,\n",
              " 'label': 6048,\n",
              " 'boundaries': 7483,\n",
              " 'across': 637,\n",
              " 'august': 6995,\n",
              " 'considering': 1068,\n",
              " 'capable': 2249,\n",
              " 'sort': 431,\n",
              " 'wake': 3289,\n",
              " 'hardcore': 4207,\n",
              " 'promising': 2427,\n",
              " 'rupert': 7284,\n",
              " \"o'brien\": 7804,\n",
              " 'extended': 3843,\n",
              " 'concentrates': 9365,\n",
              " 'northam': 7484,\n",
              " 'consisted': 9276,\n",
              " 'flavor': 6896,\n",
              " 'clueless': 5752,\n",
              " 'adams': 4600,\n",
              " 'passionate': 4386,\n",
              " 'each': 256,\n",
              " 'demonic': 5978,\n",
              " 'distracted': 7135,\n",
              " 'spice': 6710,\n",
              " 'vhs': 1855,\n",
              " 'examine': 8301,\n",
              " \"she'd\": 6448,\n",
              " 'hey': 1399,\n",
              " \"she's\": 441,\n",
              " 'u': 1205,\n",
              " 'motel': 7704,\n",
              " 'plodding': 7186,\n",
              " 'former': 1137,\n",
              " 'paperhouse': 9669,\n",
              " 'strung': 7582,\n",
              " 'zero': 1455,\n",
              " 'newspaper': 3993,\n",
              " 'masterpiece': 990,\n",
              " 'mentions': 4898,\n",
              " 'africa': 2414,\n",
              " 'tacky': 5236,\n",
              " 'engaged': 3952,\n",
              " 'mill': 4208,\n",
              " 'hour': 533,\n",
              " 'recall': 2282,\n",
              " 'sucks': 1869,\n",
              " 'remain': 2415,\n",
              " 'stubborn': 9277,\n",
              " 'ford': 2107,\n",
              " 'colman': 8070,\n",
              " 'biography': 5040,\n",
              " 'homicide': 6070,\n",
              " 'needs': 737,\n",
              " 'acts': 1420,\n",
              " 'sacred': 9787,\n",
              " 'kitty': 5684,\n",
              " 'sophistication': 8438,\n",
              " 'brady': 4142,\n",
              " 'dragon': 2784,\n",
              " 'heartfelt': 5347,\n",
              " 'appeals': 6449,\n",
              " 'comedic': 1716,\n",
              " 'compound': 9670,\n",
              " 'viewers': 796,\n",
              " 'mystery': 735,\n",
              " 'repeating': 5685,\n",
              " 'rhys': 9477,\n",
              " 'engaging': 1727,\n",
              " 'edged': 9998,\n",
              " 'perry': 4049,\n",
              " \"they'll\": 3663,\n",
              " 'extraordinary': 2801,\n",
              " 'backed': 6711,\n",
              " 'top': 349,\n",
              " 'razor': 6996,\n",
              " 'mercilessly': 9897,\n",
              " 'ton': 5852,\n",
              " 'tom': 826,\n",
              " 'lifts': 8439,\n",
              " 'godfather': 3517,\n",
              " 'eggs': 9671,\n",
              " 'charm': 1381,\n",
              " 'services': 7271,\n",
              " 'rebels': 7583,\n",
              " 'chock': 8302,\n",
              " 'ebert': 6450,\n",
              " 'premise': 862,\n",
              " 'foreign': 2188,\n",
              " 'point': 212,\n",
              " 'expensive': 3268,\n",
              " 'screened': 7929,\n",
              " 'variation': 8021,\n",
              " 'politician': 5853,\n",
              " 'widescreen': 5632,\n",
              " 'century': 1116,\n",
              " 'tashan': 7930,\n",
              " '1965': 8911,\n",
              " '1967': 7169,\n",
              " 'knock': 3295,\n",
              " 'foolish': 6392,\n",
              " 'candle': 7584,\n",
              " 'though': 150,\n",
              " 'manipulate': 8802,\n",
              " 'abusive': 4594,\n",
              " 'underused': 9672,\n",
              " 'murphy': 2692,\n",
              " 'stripped': 9479,\n",
              " 'scarlet': 8303,\n",
              " 'cure': 4317,\n",
              " 'stripper': 8787,\n",
              " 'utterly': 1253,\n",
              " 'implied': 6269,\n",
              " 'portraying': 2264,\n",
              " 'literary': 5291,\n",
              " 'pleasing': 5753,\n",
              " 'entire': 435,\n",
              " 'rivers': 6997,\n",
              " 'fat': 1921,\n",
              " 'archer': 9111,\n",
              " 'healing': 8934,\n",
              " 'escaped': 3953,\n",
              " 'closing': 2721,\n",
              " 'didnt': 9278,\n",
              " 'continuity': 2385,\n",
              " 'varied': 7187,\n",
              " 'holds': 1776,\n",
              " 'suspend': 4983,\n",
              " 'profile': 7485,\n",
              " 'watch': 105,\n",
              " 'incompetence': 9368,\n",
              " 'chasing': 3186,\n",
              " 'subsequently': 7705,\n",
              " 'grendel': 8788,\n",
              " 'grayson': 5080,\n",
              " 'blatant': 4143,\n",
              " 'lively': 4763,\n",
              " 'sexual': 860,\n",
              " 'yard': 5041,\n",
              " 'yarn': 8440,\n",
              " 'reaches': 4230,\n",
              " 'reached': 3819,\n",
              " 'spelling': 8441,\n",
              " 'sweden': 7188,\n",
              " 'have': 27,\n",
              " 'prisoner': 4765,\n",
              " 'disease': 3496,\n",
              " 'occasion': 4082,\n",
              " 'hamlet': 3419,\n",
              " 'knowledge': 1856,\n",
              " 'perfection': 3202,\n",
              " 'teams': 6270,\n",
              " 'showdown': 4900,\n",
              " 'bruno': 6361,\n",
              " 'incarnation': 9673,\n",
              " 'antics': 3870,\n",
              " 'russ': 7486,\n",
              " 'joke': 974,\n",
              " 'equal': 3214,\n",
              " 'fassbinder': 7706,\n",
              " \"it's\": 44,\n",
              " \"it'd\": 9898,\n",
              " 'locales': 9112,\n",
              " 'meredith': 7931,\n",
              " 'frustrating': 5128,\n",
              " 'powell': 2591,\n",
              " 'exceedingly': 9899,\n",
              " 'stores': 5686,\n",
              " 'griffith': 5177,\n",
              " 'resolved': 6271,\n",
              " 'doyle': 7932,\n",
              " 'like': 39,\n",
              " 'vibrant': 5754,\n",
              " 'admitted': 6998,\n",
              " 'chick': 2283,\n",
              " 'hair': 1152,\n",
              " 'recommendation': 5491,\n",
              " 'hysterically': 7272,\n",
              " 'lieutenant': 9279,\n",
              " 'uptight': 8442,\n",
              " 'introduces': 4318,\n",
              " 'rushed': 3311,\n",
              " 'rushes': 9480,\n",
              " \"'80s\": 7422,\n",
              " 'coke': 6803,\n",
              " 'flip': 7807,\n",
              " 'thorn': 9113,\n",
              " 'circus': 5600,\n",
              " 'dressed': 1809,\n",
              " 'detail': 1588,\n",
              " 'dresses': 5349,\n",
              " \"daughter's\": 5568,\n",
              " \"ted's\": 9900,\n",
              " 'harriet': 6451,\n",
              " 'direct': 1503,\n",
              " 'nail': 4422,\n",
              " 'doubt': 823,\n",
              " 'selected': 6545,\n",
              " 'revolves': 3053,\n",
              " 'revolver': 8179,\n",
              " 'liberty': 8180,\n",
              " 'leaves': 888,\n",
              " 'excellent': 320,\n",
              " 'salvage': 7808,\n",
              " 'estate': 3518,\n",
              " 'attract': 5687,\n",
              " 'ceremony': 8470,\n",
              " 'keen': 5854,\n",
              " 'drummer': 8444,\n",
              " 'description': 2785,\n",
              " 'insecure': 9901,\n",
              " 'parallel': 4679,\n",
              " 'amid': 8445,\n",
              " 'upside': 6804,\n",
              " 'succeeds': 2879,\n",
              " 'detroit': 7189,\n",
              " 'newly': 4699,\n",
              " 'independence': 5755,\n",
              " 'associate': 8181,\n",
              " 'days': 503,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO0CkecjJDL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify an embedding dimension\n",
        "\n",
        "embedding_dim=16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFBZOlp3JDL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a model using Sequential:\n",
        "#     1. Embedding layer\n",
        "#     2. GlobalAveragePooling1D\n",
        "#     3. Dense\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw9qhtlPJDL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sequential API refresher: use the Model to build the same model\n",
        "\n",
        "model1= tf.keras.Sequential([\n",
        "                            tf.keras.layers.Embedding(input_dim=max_index_value +1, output_dim=embedding_dim,mask_zero=False),\n",
        "                            tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                            tf.keras.layers.Dense(units=1,activation='sigmoid')\n",
        "])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NCXnIQuph7S",
        "colab_type": "code",
        "outputId": "c57f548b-d334-44a9-d4ec-132def1ca034",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "model1.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_4 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLoISWHWoEBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Functional API\n",
        "review_seq= tf.keras.Input((None,))\n",
        "embedding_seq= tf.keras.layers.Embedding(input_dim=max_index_value +1, output_dim=embedding_dim,mask_zero=False)(review_seq)\n",
        "avg_embedding= tf.keras.layers.GlobalAveragePooling1D()(embedding_seq)\n",
        "positive_probability= tf.keras.layers.Dense(units=1,activation='sigmoid')(avg_embedding)\n",
        "model2 = tf.keras.Model(inputs=review_seq,outputs= positive_probability)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf6oaEvTCKxV",
        "colab_type": "code",
        "outputId": "97df2a99-b57c-4566-b489-cb79cfaf44f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_10 (Embedding)     (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_5 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrX43gwPJDL-",
        "colab_type": "text"
      },
      "source": [
        "#### Compile, train, and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVfI_1EoJDL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model with a binary cross-entropy loss\n",
        "\n",
        "model2.compile(loss='binary_crossentropy', metrics=['accuracy'],optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvR-O7wGJDMC",
        "colab_type": "code",
        "outputId": "e8dc8dae-ffd1-4131-bc5f-5efcf919bfa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "# Train the model using .fit(), savng its history\n",
        "\n",
        "history= model2.fit(x_train,y_train,epochs=5,batch_size=32,validation_data=(x_test,y_test),validation_steps=20)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4193 - accuracy: 0.8577 - val_loss: 0.4259 - val_accuracy: 0.8344\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4078 - accuracy: 0.8614 - val_loss: 0.4141 - val_accuracy: 0.8438\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3938 - accuracy: 0.8657 - val_loss: 0.4001 - val_accuracy: 0.8438\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3777 - accuracy: 0.8709 - val_loss: 0.3845 - val_accuracy: 0.8578\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3608 - accuracy: 0.8752 - val_loss: 0.3695 - val_accuracy: 0.8656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ind0d_gvJDMG",
        "colab_type": "code",
        "outputId": "07205c30-c4c0-410e-b68f-31e23a60530f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHcNqGnWJDMH",
        "colab_type": "text"
      },
      "source": [
        "#### The TensorFlow embedding projector\n",
        "\n",
        "The Tensorflow embedding projector can be found [here](https://projector.tensorflow.org/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVP4G9X0JDMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Retrieve the embedding layer's weights from the trained model\n",
        "\n",
        "weights = model2.layers[1].get_weights()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10TN6OhRyQax",
        "colab_type": "code",
        "outputId": "d8e1592f-7935-4e13-bea1-97c1e00f00de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My Drive/DL_DATASet/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/DL_DATASet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHd29nfZJDMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the word Embeddings to tsv files\n",
        "# Two files: \n",
        "#     one contains the embedding labels (meta.tsv),\n",
        "#     one contains the embeddings (vecs.tsv)\n",
        "\n",
        "import io\n",
        "from os import path\n",
        "\n",
        "#out_v = io.open(path.join('content/drive/My Drive/ DL_DATASet/', 'vecs.tsv'), 'w', encoding='utf-8')\n",
        "#out_m = io.open(path.join('content/drive/My Drive/ DL_DATASet/', 'meta.tsv'), 'w', encoding='utf-8')\n",
        "\n",
        "out_v = io.open(('vecs.tsv'),'w',encoding='utf-8')\n",
        "out_m=io.open(('meta.tsv'),'w',encoding='utf-8')\n",
        "k = 0\n",
        "\n",
        "for word, token in imdb_word_index.items():\n",
        "    if k != 0:\n",
        "        out_m.write('\\n')\n",
        "        out_v.write('\\n')\n",
        "    \n",
        "    out_v.write('\\t'.join([str(x) for x in weights[token]]))\n",
        "    out_m.write(word)\n",
        "    k += 1\n",
        "    \n",
        "out_v.close()\n",
        "out_m.close()\n",
        "# beware large collections of embeddings!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ti4kMquJDML",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## Recurrent neural network layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hrm6Q2jJDMM",
        "colab_type": "text"
      },
      "source": [
        "#### Initialize and pass an input to a SimpleRNN layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM7uSwkQJDMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a SimpleRNN layer and test it\n",
        "\n",
        "simplernn_layer = tf.keras.layers.SimpleRNN(units=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_YJUyrEJDMT",
        "colab_type": "code",
        "outputId": "f6cf873f-f6f6-447d-c4e9-f74b956dccc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# Note that only the final cell output is returned\n",
        "# RNN input dim( batch, seq.length, features)\n",
        "seq= tf.constant([[ [1.,1.,3.],[2.,8.,7.],[56.,156.,9.],[33.,756.,90.] ]])\n",
        "seq"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 3), dtype=float32, numpy=\n",
              "array([[[  1.,   1.,   3.],\n",
              "        [  2.,   8.,   7.],\n",
              "        [ 56., 156.,   9.],\n",
              "        [ 33., 756.,  90.]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAhAQPt9VyNJ",
        "colab_type": "code",
        "outputId": "ca32235c-8d6a-4007-804a-3ce350259641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "layer_output=simplernn_layer(seq)\n",
        "layer_output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
              "array([[ 1.       , -1.       , -1.       , -1.       , -1.       ,\n",
              "         1.       ,  1.       ,  1.       , -1.       , -1.       ,\n",
              "        -1.       , -1.       ,  1.       , -0.9988768, -1.       ,\n",
              "        -1.       ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_rwdZtmJDMV",
        "colab_type": "text"
      },
      "source": [
        "#### Load and transform the IMDB review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qvAtycIpH1aA",
        "colab": {}
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49rJuSFmJDMV",
        "colab_type": "code",
        "outputId": "4cd005b3-0356-4bfd-8f23-e617febcf93b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Load the dataset\n",
        "(x_train, y_train),(x_test,y_test)= get_and_pad_imdb_dataset(maxlen= 250)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwUHcFKwH4wh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfyqmfOXJDMX",
        "colab_type": "code",
        "outputId": "7e90b887-7595-475f-fcd8-1c8ce51de529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Get the word index using get_imdb_word_index()\n",
        "\n",
        "imdb_word_index= get_imdb_word_index()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR7y1e-xJDMd",
        "colab_type": "text"
      },
      "source": [
        "#### Create a recurrent neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tym76m2dIVOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the maximum index value\n",
        "max_index_value = max(imdb_word_index.values() )\n",
        "max_index_value\n",
        "embedding_dim = 16 \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tO953-oJDMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using Sequential, build the model:\n",
        "# 1. Embedding.\n",
        "# 2. LSTM.\n",
        "# 3. Dense.\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                     tf.keras.layers.Embedding(input_dim= max_index_value+1 , output_dim=embedding_dim,mask_zero=True),\n",
        "                     tf.keras.layers.LSTM(units=16),\n",
        "                     tf.keras.layers.Dense(units=1,activation='sigmoid')])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v076l5CUJDMf",
        "colab_type": "text"
      },
      "source": [
        "#### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRRXW5mPJDMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model with binary cross-entropy loss\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer= 'adam')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sEqnZ22q-Qy",
        "colab_type": "code",
        "outputId": "6662a95f-21e0-40b0-827c-ccbafd7d9b3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 16)                2112      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 162,145\n",
            "Trainable params: 162,145\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "216PeHZFJDMi",
        "colab_type": "code",
        "outputId": "e1e3f3a0-2a6c-42cb-a5cd-930767207a20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "# Fit the model and save its training history\n",
        "history = model.fit(x_train,y_train,epochs= 3, batch_size=32)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "782/782 [==============================] - 393s 503ms/step - loss: 0.4078 - accuracy: 0.8131\n",
            "Epoch 2/3\n",
            "782/782 [==============================] - 392s 501ms/step - loss: 0.2301 - accuracy: 0.9142\n",
            "Epoch 3/3\n",
            "782/782 [==============================] - 392s 502ms/step - loss: 0.1765 - accuracy: 0.9372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NVXF1TSJDMj",
        "colab_type": "text"
      },
      "source": [
        "#### Plot learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms9VW07lJDMk",
        "colab_type": "code",
        "outputId": "f089a8a8-55ec-4ca3-f7b7-c4bc254716f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-14f5d334cc79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0macc\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mval_acc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mloss\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_accuracy'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AAyEd6wJDMm",
        "colab_type": "text"
      },
      "source": [
        "#### Make predictions with the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk9CHYLiJDMo",
        "colab_type": "code",
        "outputId": "c0d632e4-325d-4980-fb1c-845018045f44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# View the first test data example sentence\n",
        "# (invert the word index)\n",
        "inv_imdb_word_index= { value:key for key, value in imdb_word_index.items()}\n",
        "[inv_imdb_word_index[index] for index in x_test[0] if index>2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ignore',\n",
              " 'the',\n",
              " 'bad',\n",
              " 'reviews',\n",
              " 'on',\n",
              " 'here',\n",
              " 'this',\n",
              " 'film',\n",
              " 'is',\n",
              " 'awesome',\n",
              " 'just',\n",
              " 'before',\n",
              " 'dawn',\n",
              " 'is',\n",
              " 'a',\n",
              " 'great',\n",
              " 'example',\n",
              " 'of',\n",
              " 'what',\n",
              " 'can',\n",
              " 'be',\n",
              " 'done',\n",
              " 'in',\n",
              " 'a',\n",
              " 'film',\n",
              " 'with',\n",
              " 'a',\n",
              " 'minimal',\n",
              " 'budget',\n",
              " 'if',\n",
              " 'you',\n",
              " 'have',\n",
              " 'a',\n",
              " 'dedicated',\n",
              " 'crew',\n",
              " 'decent',\n",
              " 'script',\n",
              " 'and',\n",
              " 'a',\n",
              " 'cool',\n",
              " 'idea',\n",
              " 'for',\n",
              " 'a',\n",
              " 'film',\n",
              " \"it's\",\n",
              " 'a',\n",
              " 'hell',\n",
              " 'of',\n",
              " 'a',\n",
              " 'lot',\n",
              " 'of',\n",
              " 'fun',\n",
              " 'br',\n",
              " 'br',\n",
              " 'i',\n",
              " 'enjoyed',\n",
              " 'it',\n",
              " 'a',\n",
              " 'lot',\n",
              " 'more',\n",
              " 'than',\n",
              " 'most',\n",
              " 'other',\n",
              " \"80's\",\n",
              " 'slashers',\n",
              " 'because',\n",
              " 'the',\n",
              " 'killer',\n",
              " 'is',\n",
              " 'so',\n",
              " 'unique',\n",
              " 'wrong',\n",
              " 'turn',\n",
              " 'ripped',\n",
              " 'this',\n",
              " 'movie',\n",
              " 'off',\n",
              " 'something',\n",
              " 'fierce',\n",
              " \"there's\",\n",
              " 'plenty',\n",
              " 'of',\n",
              " 'blood',\n",
              " 'and',\n",
              " 'scares',\n",
              " 'my',\n",
              " 'girlfriend',\n",
              " 'was',\n",
              " 'freaked',\n",
              " 'out',\n",
              " 'and',\n",
              " 'she',\n",
              " 'watches',\n",
              " 'almost',\n",
              " 'everything',\n",
              " 'with',\n",
              " 'me',\n",
              " 'and',\n",
              " \"doesn't\",\n",
              " \"it's\",\n",
              " 'got',\n",
              " 'that',\n",
              " 'creepiness',\n",
              " 'to',\n",
              " 'it',\n",
              " 'br',\n",
              " 'br',\n",
              " \"i'd\",\n",
              " 'say',\n",
              " 'that',\n",
              " 'just',\n",
              " 'before',\n",
              " 'dawn',\n",
              " 'is',\n",
              " 'the',\n",
              " 'best',\n",
              " 'early',\n",
              " \"80's\",\n",
              " 'slasher',\n",
              " 'out',\n",
              " 'there',\n",
              " 'i',\n",
              " 'really',\n",
              " 'enjoyed',\n",
              " 'it',\n",
              " 'br',\n",
              " 'br',\n",
              " '8',\n",
              " 'out',\n",
              " 'of',\n",
              " '10',\n",
              " 'kids']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blf6in2dJDMs",
        "colab_type": "code",
        "outputId": "4f104e51-f943-43d8-d4c0-73c15c0f92e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Get the model prediction using model.predict()\n",
        "model.predict(x_test[None,0,:])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.98772544]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6eyT_3NgmEV",
        "colab_type": "code",
        "outputId": "402b996a-2762-4f18-d080-e80a13bd72b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "x_test[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    1, 2753,    3,   77,  856,   22,\n",
              "        132,   13,   21,    8, 1189,   42,  158, 3421,    8,    5,   86,\n",
              "        462,    6,   50,   69,   29,  223,   10,    5,   21,   18,    5,\n",
              "       3721,  351,   47,   24,   27,    5, 4326, 1050,  541,  228,    4,\n",
              "          5,  645,  325,   17,    5,   21,   44,    5,  608,    6,    5,\n",
              "        175,    6,  252,    9,    9,   12,  509,   11,    5,  175,   52,\n",
              "         73,   90,   84, 1354, 7415,   87,    3,  454,    8,   37,  954,\n",
              "        354,  470, 3313,   13,   19,  124,  141, 8479,  224,  957,    6,\n",
              "        540,    4, 2628,   60,  979,   15, 9019,   45,    4,   58, 3630,\n",
              "        219,  284,   18,   71,    4,  151,    2,   44,  187,   14, 9331,\n",
              "          7,   11,    9,    9,  473,  134,   14,   42,  158, 3421,    8,\n",
              "          3,  117,  401, 1354, 1178,   45,   49,   12,   65,  509,   11,\n",
              "          9,    9,  708,   45,    6,  157,  361], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbpqS5z2kjVd",
        "colab_type": "code",
        "outputId": "61cf8409-3d28-4dc2-bd71-3fa3be8164e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "[inv_imdb_word_index[index] for index in x_test[0] if index>2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['please',\n",
              " 'give',\n",
              " 'this',\n",
              " 'one',\n",
              " 'a',\n",
              " 'miss',\n",
              " 'br',\n",
              " 'br',\n",
              " 'and',\n",
              " 'the',\n",
              " 'rest',\n",
              " 'of',\n",
              " 'the',\n",
              " 'cast',\n",
              " 'rendered',\n",
              " 'terrible',\n",
              " 'performances',\n",
              " 'the',\n",
              " 'show',\n",
              " 'is',\n",
              " 'flat',\n",
              " 'flat',\n",
              " 'flat',\n",
              " 'br',\n",
              " 'br',\n",
              " 'i',\n",
              " \"don't\",\n",
              " 'know',\n",
              " 'how',\n",
              " 'michael',\n",
              " 'madison',\n",
              " 'could',\n",
              " 'have',\n",
              " 'allowed',\n",
              " 'this',\n",
              " 'one',\n",
              " 'on',\n",
              " 'his',\n",
              " 'plate',\n",
              " 'he',\n",
              " 'almost',\n",
              " 'seemed',\n",
              " 'to',\n",
              " 'know',\n",
              " 'this',\n",
              " \"wasn't\",\n",
              " 'going',\n",
              " 'to',\n",
              " 'work',\n",
              " 'out',\n",
              " 'and',\n",
              " 'his',\n",
              " 'performance',\n",
              " 'was',\n",
              " 'quite',\n",
              " 'so',\n",
              " 'all',\n",
              " 'you',\n",
              " 'madison',\n",
              " 'fans',\n",
              " 'give',\n",
              " 'this',\n",
              " 'a',\n",
              " 'miss']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCyKBsZHJDMt",
        "colab_type": "code",
        "outputId": "d3a5ee76-6854-4dd9-f25e-3a49e641c48e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Get the corresponding label\n",
        "y_test[0]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpaI83PlJDMv",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_6\"></a>\n",
        "## Stacked RNNs and the Bidirectional wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Qr4kOevKRt8"
      },
      "source": [
        "#### Load and transform the IMDb review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i06LdJiXKRt9",
        "colab": {}
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EjA8JlQVKRuB",
        "outputId": "2edc258e-995d-4c7d-cba4-c736fdf46558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "(x_train,y_train),(x_test,y_test)=get_and_pad_imdb_dataset(num_words=1000,maxlen=250)\n",
        "                                                           "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7iBFGx9_KRuD",
        "colab": {}
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "29lcV0UGKRuF",
        "outputId": "9162733a-e7b0-41c3-f498-f2f288be1732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Get the word index using get_imdb_word_index()\n",
        "imdb_word_index= get_imdb_word_index(num_words= 5000)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh_Vv9-5JDM1",
        "colab_type": "text"
      },
      "source": [
        "#### Build stacked and bidirectional recurrent models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6Sy-gMyLLEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the maximum index value and specify an embedding dimension\n",
        "max_index_value=max(imdb_word_index.values())\n",
        "embedding_dim=16\n",
        "print(max_index_value)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89yWIAFdJDM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using Sequential, build a stacked LSTM model via return_sequences=True\n",
        "model= tf.keras.Sequential([\n",
        "                            tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim,mask_zero=True),\n",
        "                            tf.keras.layers.LSTM(units=32,return_sequences=True),   # return_Seq=True will make layer to return 3 dim output\n",
        "                            tf.keras.layers.LSTM(units=32,return_sequences=False),\n",
        "                            tf.keras.layers.Dense(units=1,activation='sigmoid')\n",
        "\n",
        "\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV1-InvrGIxt",
        "colab_type": "code",
        "outputId": "88214038-ae78-4a9d-d0eb-bda1c1212228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 16)          80016     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, None, 32)          6272      \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 94,641\n",
            "Trainable params: 94,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-34ZWvRJDM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using Sequential, build a bidirectional RNN with merge_mode='sum'\n",
        "\n",
        "model1= tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim,mask_zero=True),\n",
        "                             tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=8),merge_mode='sum',backward_layer=tf.keras.layers.GRU(units=8,go_backwards=True)),\n",
        "                             tf.keras.layers.Dense(units=1,activation='sigmoid')\n",
        "\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ6ttwmlGNn3",
        "colab_type": "code",
        "outputId": "1f4d4ae4-6add-4e3a-ca1d-837129afbb46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, None, 16)          80016     \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 8)                 1424      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 81,449\n",
            "Trainable params: 81,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub2bE1A5GNkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSpOIOCmJDM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a model featuring both stacked recurrent layers and a bidirectional layer\n",
        "model2= tf.keras.Sequential([tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim,mask_zero=True),\n",
        "                             tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=8,return_sequences=True),merge_mode='concat'),\n",
        "                             tf.keras.layers.GRU(units=8,return_sequences=False),\n",
        "                             tf.keras.layers.Dense(units=1,activation='sigmoid')\n",
        "                             ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHx4TlfKGUdX",
        "colab_type": "code",
        "outputId": "40dc0b57-8188-4623-f24b-97ec738b2dcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, None, 16)          80016     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, None, 16)          1600      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 8)                 624       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 82,249\n",
            "Trainable params: 82,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3srEhqCJDM7",
        "colab_type": "text"
      },
      "source": [
        "#### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5Dy_C6-JDM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "model2.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er8atiBoJDM9",
        "colab_type": "code",
        "outputId": "5956e003-c56f-48e3-e267-f4621a50f9e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "# Train the model, saving its history\n",
        "\n",
        "history= model2.fit(x_train,y_train,epochs=3,batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "782/782 [==============================] - 1737s 2s/step - loss: 0.4266 - accuracy: 0.7922\n",
            "Epoch 2/3\n",
            "782/782 [==============================] - 1738s 2s/step - loss: 0.3095 - accuracy: 0.8698\n",
            "Epoch 3/3\n",
            "111/782 [===>..........................] - ETA: 24:26 - loss: 0.2741 - accuracy: 0.8925"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLOLtBKwJDNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}